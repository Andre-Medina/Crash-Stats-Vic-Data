{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning inital dataframe\n",
    "\n",
    "Now we know what the data looks like, we can start to filter it a bit more and tidy up the data\n",
    "\n",
    "This file is used for cleaning the raw data into roughly cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import sys\n",
    "\n",
    "ROOT_DIR = '../'\n",
    "sys.path.insert(1, '../production_code/')\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "accidents = pd.read_csv(ROOT_DIR + ACCIDENT_DATA_GENERAL_DIR)\n",
    "node = pd.read_csv(ROOT_DIR + ACCIDENT_DATA_NODE_DIR)\n",
    "person = pd.read_csv(ROOT_DIR + ACCIDENT_DATA_PERSON_DIR)\n",
    "atmospheric = pd.read_csv(ROOT_DIR + ACCIDENT_DATA_ATMOSPHERIC_DIR)\n",
    "road_cond = pd.read_csv(ROOT_DIR + ACCIDENT_DATA_ROAD_COND_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data model\n",
    "\n",
    "features\n",
    "\n",
    "| group name | column name | data type | description | original dataset |\n",
    "| ---- | ----- | ---- | ---- | ---- |\n",
    "| time | date | pd.datetime |  | accident\n",
    "|  | day of week | pd.datetime |  | accident\n",
    "|  | time of day (hour) | pd.datetime |  | accident\n",
    "| | light level | int | dark (any) = 0, dawn/dusk = 1, day = 2 | LIGHT_COND, accident\n",
    "| | | | | \n",
    "| location | node_id | int | | node |\n",
    "| | lga | string | local area | node |\n",
    "| | region | string | | node |\n",
    "| | long | float | longitude | node |\n",
    "| | lat | float | latitude | node |\n",
    "| |  | | |\n",
    "| atmospheric | 1: clear         | bool |            | atmostpheric\n",
    "|             | 2: raining       | bool |            | atmostpheric\n",
    "|             | 3: snowing       | bool |            | atmostpheric\n",
    "|             | 4: fog           | bool |            | atmostpheric\n",
    "|             | 5: smoke         | bool |            | atmostpheric\n",
    "|             | 6: dust          | bool |            | atmostpheric\n",
    "|             | 7: winds         | bool |            | atmostpheric\n",
    "|             | 9: unknown       | bool | remove unknown | atmostpheric\n",
    "| | | | |\n",
    "| road_cond   | 1: dry           | bool |           | road condition\n",
    "|             | 2: wet           | bool |           | road condition\n",
    "|             | 3: muddy         | bool |           | road condition\n",
    "|             | 4: snowy         | bool |           | road condition\n",
    "|             | 5: icy           | bool |           | road condition\n",
    "|             | 9: unknown       | bool | remove unknown  | road condition\n",
    "| | | | |\n",
    "\n",
    "labels\n",
    "\n",
    "| column name | data type | description | original dataset |\n",
    "| ----- | ---- | ---- | ---- |\n",
    "| police_needed | int | number of police for colision bin | POLICE_ATTENDED, accident |\n",
    "| ambulance_needed | int | number of ambulance needed for that colision bin | to investigate, mix of TAKEN_HOSPITAL in PERSON and if injuries are serious in ACCIDENT | \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    " ### Abulance needed\n",
    "\n",
    "assuming an ambulace is called if\n",
    "\n",
    "there are more than \n",
    "- 5 people involved in a crash ? (didnt include)\n",
    "- any person in the crash has an inj_level > 0\n",
    "- any person was taken to the hospital\n",
    "\n",
    "only calls one ambulance no matter number of people, to keep inline with number of police\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# viewing uniqueness of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.groupby('ACCIDENT_NO')['ACCIDENTDATE'].count().sort_values()   # no duplicates for accidnets no, theyre unique\n",
    "\n",
    "\n",
    "node.groupby('ACCIDENT_NO')['NODE_ID'].count().sort_values()\n",
    "node.query('ACCIDENT_NO == \"T20170021373\"')    # dueplicated nodes per accident are due to issues with postcode double ups, not in multi location\n",
    "\n",
    "\n",
    "\n",
    "person.groupby('ACCIDENT_NO')['PERSON_ID'].count().sort_values()     # duplicate ACCIDENT_NO for multiple perople in single colision\n",
    "person.query('ACCIDENT_NO == \"T20130018492\"')   \n",
    "\n",
    "atmospheric.groupby('ACCIDENT_NO')['ATMOSPH_COND'].count().sort_values()     \n",
    "atmospheric.query('ACCIDENT_NO == \"T20190001830\"')           # several conditions like winds and rain, need to factor in, probably pivot as seperate columns\n",
    "\n",
    "\n",
    "\n",
    "road_cond.groupby('ACCIDENT_NO')['SURFACE_COND'].count().sort_values()\n",
    "road_cond.query('ACCIDENT_NO == \"T20070019368\"')          # same as atmospheric, several conditions can be met"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filtering and transforming "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing type\n",
    "accidents['ACCIDENT_NO'] = accidents['ACCIDENT_NO'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date\n",
    "\n",
    "# removing na dates and times\n",
    "accidents = accidents.dropna(subset=['ACCIDENTDATE'])\n",
    "accidents = accidents.dropna(subset=['ACCIDENTTIME'])\n",
    "\n",
    "# only keeping more recent data from 2016 prior, new data will be more accurate\n",
    "accidents = accidents[pd.to_datetime(accidents['ACCIDENTDATE']) > pd.to_datetime(EARLIEST_DATE)].reset_index(drop = True)\n",
    "accidents.head(3)\n",
    "\n",
    "# combine date strings\n",
    "accidents.loc[:,'date'] = pd.to_datetime(accidents[['ACCIDENTDATE','ACCIDENTTIME']].apply(lambda x: x[0] + \" \" + x[1] , axis = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding more date breakdowns for testing\n",
    "accidents.loc[:,'day'] = accidents.loc[:,'date'].dt.dayofweek \n",
    "accidents.loc[:,'hour'] = accidents.loc[:,'date'].dt.hour \n",
    "accidents.loc[:,'hour_bin'] = pd.cut(accidents.loc[:,'hour'], [0, 6, 12, 18, 24] , labels=[0,1,2,3], right=False).cat.codes\n",
    "accidents.loc[:,'season'] = accidents.loc[:,'date'].dt.month % 12 // 3 + 1\n",
    "accidents.loc[:,'month'] = accidents.loc[:,'date'].dt.month\n",
    "accidents.loc[:,'year'] = accidents.loc[:,'date'].dt.year\n",
    "accidents.loc[:,'date_stamp'] = accidents.loc[:,'date'].dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# light conditions\n",
    "\n",
    "# dont remove unknown lighting conditions, didnt end up using it\n",
    "# accidents = accidents.query(\"LIGHT_CONDITION != 9\")\n",
    "\n",
    "# converts conditions to 0-2 scale of daylight\n",
    "accidents.loc[:,'day_light'] = accidents['LIGHT_CONDITION'].apply(lambda light_level: 3 - min(light_level, 3))    \n",
    "\n",
    "# printing\n",
    "accidents.groupby('LIGHT_CONDITION')['day_light'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing when unsure if police attened or not, didnt remove many rows\n",
    "accidents = accidents.query(\"POLICE_ATTEND != 9\")   \n",
    "\n",
    "# shifts police attened to boolean yes or no\n",
    "accidents.loc[:,'police_needed'] = accidents['POLICE_ATTEND'].apply(lambda x: 2 - x)\n",
    "\n",
    "# printing\n",
    "accidents.groupby('POLICE_ATTEND')['police_needed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns of interest\n",
    "accidents_of_interest = ['date','date_stamp', 'day', 'hour', 'hour_bin', 'season', 'month', 'day_light']\n",
    "accidents_label_columns = ['police_needed']\n",
    "id_columns = ['ACCIDENT_NO']\n",
    "\n",
    "# printing data\n",
    "accidents[id_columns + accidents_of_interest + accidents_label_columns].head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping instances with ids that exist\n",
    "# person = person[person['ACCIDENT_NO'].isin(accidents['ACCIDENT_NO'])]\n",
    "\n",
    "# converting injury level to number\n",
    "person.loc[:,'injury_level'] = person['INJ_LEVEL'].apply(pd.to_numeric, errors= 'coerce')\n",
    "person = person.dropna(subset = ['injury_level'])\n",
    "\n",
    "# calculating if individual needed an ambulance\n",
    "person.loc[:,'ambulance_needed'] = person[['injury_level','TAKEN_HOSPITAL']].apply(lambda x: (x['injury_level'] < 4) or (x['TAKEN_HOSPITAL'] == 'Y'), axis = 1)    \n",
    "\n",
    "# person.groupby(['INJ_LEVEL'])['ambulance_needed'].unique()   # data looks good\n",
    "\n",
    "# accidents where ambulance was needed\n",
    "person_grouped = person.groupby('ACCIDENT_NO')['ambulance_needed'].any()\n",
    "\n",
    "# pivots to summarize ambulance data per crash\n",
    "person_pivotted = person\\\n",
    "    .pivot_table(index = \"ACCIDENT_NO\", values = 'ambulance_needed', aggfunc = \"max\")\\\n",
    "    .fillna(0)\\\n",
    "    .applymap(lambda x: min(x, 1))\\\n",
    "    .reset_index()\n",
    "\n",
    "# of interest columns\n",
    "person_of_interest = []\n",
    "person_label_columns = ['ambulance_needed']\n",
    "\n",
    "# prints data\n",
    "person_pivotted[id_columns + person_of_interest + person_label_columns].head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping instances with ids that exist\n",
    "print(\"initial shape: \" + str(node.shape))\n",
    "# node = node[node['ACCIDENT_NO'].isin(accidents['ACCIDENT_NO'])]\n",
    "\n",
    "# reanaming columns\n",
    "node = node.rename(columns = {\n",
    "    'REGION_NAME': 'region', \n",
    "    'LGA_NAME':'lga', \n",
    "    'NODE_ID':'node_id',\n",
    "    'Lat':'lat',\n",
    "    'Long':'long'\n",
    "    })\n",
    "\n",
    "# stringifying\n",
    "node['region'] = node['region'].astype(str)\n",
    "node['lga'] = node['lga'].astype(str)\n",
    "\n",
    "# to numeric\n",
    "node.loc[:,'lat'] = node.loc[:,'lat'].apply(pd.to_numeric)\n",
    "node.loc[:,'long'] = node.loc[:,'long'].apply(pd.to_numeric)\n",
    "\n",
    "# removing blank regions\n",
    "node = node.query('region != \" \"')\n",
    "\n",
    "# printing shape to check for issues\n",
    "print(\"final shape: \" + str(node.shape))\n",
    "\n",
    "# setting of interst and printing\n",
    "node_of_interest = ['node_id','lga','region','lat','long']\n",
    "node[id_columns + node_of_interest].drop_duplicates().head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### road_cond\n",
    "\n",
    "after inital testing, simplified data as road condition tended not to be used that much and was mostly inaccuate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# road condition dictionary\n",
    "road_cond_id_to_desc = {\n",
    "    1: 'dry',\n",
    "    2: 'wet',\n",
    "    3: 'muddy',\n",
    "    4: 'snowy',\n",
    "    5: 'icy',\n",
    "    9: 'not known',\n",
    "}\n",
    "\n",
    "# simplify road conditions to dry or not\n",
    "def simpilfy_road_cond(id):\n",
    "    if id  == 1:   # dry\n",
    "        return 1   # road not dry\n",
    "    else:\n",
    "        return 0   # road not dry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"initial shape: \" + str(road_cond.shape))\n",
    "\n",
    "# only keeping instances with ids that exist, didnt need\n",
    "# road_cond = road_cond[road_cond['ACCIDENT_NO'].isin(accidents['ACCIDENT_NO'])]\n",
    "\n",
    "\n",
    "# removes unknowns,\n",
    "# road_cond = road_cond.query(\"SURFACE_COND != 9\")   # didnt need in the end\n",
    "road_cond = road_cond.dropna(subset = ['SURFACE_COND'])\n",
    "\n",
    "# simplifying conditions to either dry or not\n",
    "road_cond.loc[:,'SURFACE_COND'] = road_cond.loc[:,'SURFACE_COND'].apply(lambda x: x == 1)\n",
    "\n",
    "# OLD CODE: instead of simplifying conditions to dry or not, was breaking down into several options\n",
    "# simplifying descriptions\n",
    "# road_cond.loc[:,'Atmosph Cond Desc'] = road_cond.loc[:,'ATMOSPH_COND'].apply(lambda id: road_cond_id_to_desc[id])\n",
    "#\n",
    "# making descrions lowercase\n",
    "# road_cond.loc[:,'Surface Cond Desc'] = road_cond.loc[:,'Surface Cond Desc'].str.lower()\n",
    "# \n",
    "    # .pivot(index = \"ACCIDENT_NO\", columns = 'Surface Cond Desc', values = 'SURFACE_COND')\\\n",
    "\n",
    "# pivots to create new columns for each condition\n",
    "road_cond_pivotted = road_cond\\\n",
    "    .pivot_table(index = \"ACCIDENT_NO\", values = 'SURFACE_COND', aggfunc = \"max\")\\\n",
    "    .rename(columns = {\"SURFACE_COND\": 'dry'})\\\n",
    "    .fillna(0)\\\n",
    "    .applymap(lambda x: min(x, 1))\\\n",
    "    .reset_index()\n",
    "\n",
    "# sets of interest column and outputs data\n",
    "road_cond_of_interest = ['dry']\n",
    "road_cond_pivotted[id_columns + road_cond_of_interest].drop_duplicates().head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### atmospheric\n",
    "\n",
    "after testing, same thing, simplifying atmospheric conditions made sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atmospheric condition lookup\n",
    "atmosph_id_to_desc = {\n",
    "    1: 'clear',\n",
    "    2: 'raining',\n",
    "    3: 'snowing',\n",
    "    4: 'fog',\n",
    "    5: 'smoke',\n",
    "    6: 'dust',\n",
    "    7: 'strong winds',\n",
    "    9: 'not known',\n",
    "}\n",
    "\n",
    "# simplifies atmospheric into a few options\n",
    "def simpilfy_atmosph_id(id):\n",
    "    if id  == 1:   # clear\n",
    "        return 1\n",
    "    elif id in [2, 3]:    # snow or rain\n",
    "        return 2\n",
    "    elif id == 7:   #   wind\n",
    "        return 7\n",
    "    elif id in [4, 5, 6]:   #   fog_like\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping instances with ids that exist\n",
    "# atmospheric = atmospheric[atmospheric['ACCIDENT_NO'].isin(accidents['ACCIDENT_NO'])]\n",
    "\n",
    "# removes unknowns\n",
    "atmospheric = atmospheric.query(\"ATMOSPH_COND != 9\")\n",
    "atmospheric = atmospheric.dropna(subset = ['ATMOSPH_COND'])\n",
    "\n",
    "# simplifying conditions\n",
    "atmospheric.loc[:,'ATMOSPH_COND'] = atmospheric.loc[:,'ATMOSPH_COND'].apply(simpilfy_atmosph_id)\n",
    "\n",
    "# simplifying descriptions\n",
    "atmospheric.loc[:,'Atmosph Cond Desc'] = atmospheric.loc[:,'ATMOSPH_COND'].apply(lambda id: atmosph_id_to_desc[id])\n",
    "\n",
    "# pivots to create new columns\n",
    "atmospheric_pivotted = atmospheric\\\n",
    "    .drop_duplicates(subset = ['ACCIDENT_NO','ATMOSPH_COND'])\\\n",
    "    .pivot(index = \"ACCIDENT_NO\", columns = 'Atmosph Cond Desc', values = 'ATMOSPH_COND')\\\n",
    "    .fillna(0)\\\n",
    "    .applymap(lambda x: min(x, 1))\\\n",
    "    .reset_index()\n",
    "\n",
    "# sets of interest and prints data\n",
    "atmospheric_of_interest = ['clear', 'fog', 'raining', 'strong winds']\n",
    "atmospheric_pivotted[id_columns + atmospheric_of_interest].drop_duplicates().head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving pre merged data for analysis\n",
    "accidents.to_csv(ROOT_DIR + ROUGHLY_CLEANED_PRE_MERGE_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merging all data with accidents, removing duplicates along the way\n",
    "output = accidents[id_columns + accidents_of_interest + accidents_label_columns]\\\n",
    "    .drop_duplicates()\\\n",
    "    .merge(   \n",
    "        # adding node data for location\n",
    "        node[id_columns + node_of_interest].drop_duplicates(), \n",
    "        how='inner')\\\n",
    "    .merge(\n",
    "        # adding road condition data\n",
    "        road_cond_pivotted[id_columns + road_cond_of_interest].drop_duplicates(), \n",
    "        how='inner')\\\n",
    "    .merge(\n",
    "        # adding general weather data\n",
    "        atmospheric_pivotted[id_columns + atmospheric_of_interest].drop_duplicates(), \n",
    "        how='inner')\\\n",
    "    .merge(\n",
    "        # adding person data for ambulance needed\n",
    "        person_pivotted[id_columns + person_of_interest + person_label_columns].drop_duplicates(), \n",
    "        how='inner')\\\n",
    "\n",
    "# printing sample\n",
    "output.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing columns to chose from\n",
    "accidents_of_interest + node_of_interest + road_cond_of_interest + atmospheric_of_interest + accidents_of_interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing how it pivots\n",
    "output.pivot_table(\n",
    "    index = ['day','hour_bin','region','dry','clear', 'fog', 'raining', 'strong winds'],\n",
    "    values = accidents_label_columns + person_label_columns,\n",
    "    aggfunc = 'sum'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputting data for initial visuals\n",
    "output.to_csv(ROOT_DIR + ROUGHLY_CLEANED_DATA_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
