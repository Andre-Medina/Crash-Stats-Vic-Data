{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the data\n",
    "\n",
    "Before doing anything, we need to know what the data structure is.\n",
    "\n",
    "This file experiments with the data structure and investigates all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import sys\n",
    "\n",
    "ROOT_DIR = '../'\n",
    "sys.path.insert(1, '../production_code/')\n",
    "from constants import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2000_to_20005 is a whole seperate dataset, same columns, might ignore it for now, filter by dates\n",
    "\n",
    "## from \n",
    "\n",
    "\n",
    "| csv name | from documentation | from experimentation |\n",
    "| ---| --- | --- |\n",
    "| ACCIDENT_CHAINAGE |  | more specific location data |\n",
    "| ACCIDENT_EVENT | accident_event (sequence of events e.g. left road, rollover, caught fire) | + location of impact on car |\n",
    "| ACCIDENT_LOCATION |  | geographical location (street names no GPS) |\n",
    "| ACCIDENT | accident (basic accident details, time, severity, location) | Main dataframe, general info |\n",
    "| ATMOSPHERIC_COND | atmospheric_cond (rain, winds etc) | |\n",
    "| NODE_ID_COMPLEX_INT_ID |  |  for breaking down complex intersections |\n",
    "| NODE | Node Table with Lat/Long references | Lat/long and LGA areas |\n",
    "| PERSON | person (person based details, age, sex etc) | |\n",
    "| ROAD_SURFACE_COND | road_surface_cond (whether road was wet, dry, icy etc)  | |\n",
    "| Statistic Checks |  | some general stats |\n",
    "| SUBDCA | sub_dca (detailed codes describing accident) | eg vehicle entering or leaving intersection etc.. |\n",
    "| VEHICLE | vehicle (vehicle based data, vehicle type, make etc) | |\n",
    "\n",
    "## from documentation\n",
    "\n",
    "- accident_node (master location table - NB subset of accident table) \n",
    "\n",
    "\n",
    "## features of interest\n",
    "\n",
    "| Feature | description | dataset |\n",
    "| ---- | ---- | ---- |\n",
    "| ACCIDENT_NO | individual accident id, one id for each accident | all |\n",
    "| NODE_ID | locational node where the incident occured, 0 is unable to locate | NODE |\n",
    "| ACCIDENTDATE | date | ACCIDENT |\n",
    "| ACCIDENTTIME | time | ACCIDENT |\n",
    "| ATMOSPH_COND | int 0-9, General weather data, check crash stats apendecies | ATMOSPHERIC_COND |\n",
    "| ATMOSPH_COND_SEQ | int 0-4, not sure, ignoring | ATMOSPHERIC_COND |\n",
    "| LIGHT_CONDITION | | ACCIDENT\n",
    "| ACCIDENT_TYPE | type of colision, hit animal, ped etc... | ACCIDENT\n",
    "| SEVERITY | non injury (0) - fatal (died in 30 days) (1) | ACCIDENT\n",
    "| ROAD_GEOMETRY | Cross intersection - not at an intersection | ACCIDENT\n",
    "| POLICE_ATTEND | whether police attended or not | ACCIDENT\n",
    "| VEHICLE_ID | information of a vehicle | ACCIDENT_EVENT  \n",
    "| ATMOSPH_COND_SEQ | not sure, if the weather changes maybe? | ATMOSPHERIC_COND\n",
    "| COMPLEX_INT_NO | for breaking down complex intersections  into sub chunks | NODE_ID_COMPLEX_INT_ID\n",
    "| LGA_NAME | local goverment area | NODE\n",
    "| REGION_NAME | more granial area if needed | NODE\n",
    "| NODE_TYPE | type of node point (intersection, non intersection etc...) | NODE\n",
    "| TAKEN_HOSPITAL | is a person was taken to hospital | PERSON\n",
    "| ROAD_USER_TYPE | where the person was in realtion to the accident | PERSON\n",
    "| SURFACE_COND | road condition | ROAD_SURFACE_COND\n",
    "\n",
    "\n",
    "## ideas for the project\n",
    "\n",
    "1. Comparing intersection crash data year on year to see which intersections improve\n",
    "2. Predict number of incidents using\n",
    "    1. features\n",
    "        1.  weather data\n",
    "        2.  SURFACE_COND     \n",
    "            1.  too related to weather data?\n",
    "        3.  location data\n",
    "            1.  node, LGA, Region?\n",
    "        4. night or day\n",
    "           1. might be too related to time?\n",
    "        5. Datetime\n",
    "           1. Time of day (1, 2, 4, or 6 hour bins)\n",
    "           2. Day of week (or just weekday vs weekend etc...)\n",
    "           3. month of year (maybe creates overfitting, too granular?)\n",
    "\n",
    "    2. labels, what \n",
    "        1. count of Police attended\n",
    "        2. Mean severity (or own severity metric)\n",
    "           1. no_persons\n",
    "           2. no_vehicles\n",
    "           3. other NO_PERSON metrics\n",
    "           4. number of people taken to hospitals\n",
    "        3. straight count of incidents\n",
    "    \n",
    "    3.  to filter on\n",
    "        1. accident_type: remove non colisions?\n",
    "        2. SEVERITY: remove non injury?\n",
    "        3. POLICE_ATTEND (not known category)\n",
    "        4. unique ACCIDENT_NO\n",
    "        5. check surface condition link to weather data\n",
    "\n",
    "    1.  data sets needed\n",
    "        1.  ROAD_SURFACE_COND\n",
    "        2.  PERSON\n",
    "        3.  NODE\n",
    "        4.  ACCIDENT\n",
    "        5.  ATMOSPHERIC_COND\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENTATION\n",
    "\n",
    "## playing with the data to see what each table has to offer and what each column means\n",
    "\n",
    "Note: most of the code here is meaningless, just reminents from experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare columns\n",
    "# list(set(pd.read_csv(ROOT_DIR + DATA_RAW_DIR + 'ACCIDENT\\ACCIDENT_EVENT.csv').columns) - set(pd.read_csv(ROOT_DIR + DATA_RAW_DIR + 'ACCIDENT\\ACCIDENT.csv').columns))\n",
    "\n",
    "\n",
    "# comparing acciendent.csv from general to 2000_to_20005\n",
    "\n",
    "len(list(set(pd.read_csv(ROOT_DIR + DATA_RAW_DIR + '2000_to_2005_ACCIDENT\\ACCIDENT.csv')['ACCIDENT_NO']) - set(pd.read_csv(ROOT_DIR + DATA_RAW_DIR + 'ACCIDENT\\ACCIDENT.csv')['ACCIDENT_NO'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at any specific file\n",
    "pd.read_csv(ROOT_DIR + DATA_RAW_DIR + \"ACCIDENT/ACCIDENT_CHAINAGE.csv\").iloc[0]\n",
    "# pd.read_csv(ROOT_DIR + DATA_RAW_DIR + \"ACCIDENT/ATMOSPHERIC_COND.csv\").groupby('ATMOSPH_COND')['ATMOSPH_COND_SEQ'].unique()\n",
    "# pd.read_csv(ROOT_DIR + DATA_RAW_DIR + \"ACCIDENT/PERSON.csv\").groupby('TAKEN_HOSPITAL').count()['ACCIDENT_NO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values inside atmospheric conditions\n",
    "pd.read_csv(ROOT_DIR + DATA_RAW_DIR + \"ACCIDENT/ATMOSPHERIC_COND.csv\")['ATMOSPH_COND_SEQ'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique node ids\n",
    "len(pd.read_csv(ROOT_DIR + DATA_RAW_DIR + \"ACCIDENT/NODE.csv\")['NODE_ID'].unique())\n",
    "# len(pd.read_csv(ROOT_DIR + DATA_RAW_DIR + \"ACCIDENT/ACCIDENT_LOCATION.csv\")['NODE_ID'].unique())\n",
    "\n",
    "# looking at the node file\n",
    "pd.read_csv(ROOT_DIR + DATA_RAW_DIR + \"ACCIDENT/NODE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting node data using latitude and longitude \n",
    "\n",
    "# reading node data\n",
    "local = pd.read_csv(ROOT_DIR + DATA_RAW_DIR + \"2000_to_2005_ACCIDENT\\\\NODE.csv\")\n",
    "fig = px.scatter_mapbox(local, lat=\"Lat\", lon=\"Long\", hover_name=\"ACCIDENT_NO\") \n",
    "\n",
    "fig.update_geos(resolution=50)\n",
    "fig.update_layout( # Update the layout\n",
    ")\n",
    "fig.show() # Show the plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
