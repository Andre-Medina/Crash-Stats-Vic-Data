{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import sys\n",
    "\n",
    "ROOT_DIR = '../'\n",
    "sys.path.insert(1, '../production_code/')\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "accidents = pd.read_csv(ROOT_DIR + ACCIDENT_DATA_GENERAL_DIR)\n",
    "node = pd.read_csv(ROOT_DIR + ACCIDENT_DATA_NODE_DIR)\n",
    "person = pd.read_csv(ROOT_DIR + ACCIDENT_DATA_PERSON_DIR)\n",
    "atmospheric = pd.read_csv(ROOT_DIR + ACCIDENT_DATA_ATMOSPHERIC_DIR)\n",
    "road_cond = pd.read_csv(ROOT_DIR + ACCIDENT_DATA_ROAD_COND_DIR)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data model\n",
    "\n",
    "features\n",
    "\n",
    "| group name | column name | data type | description | original dataset |\n",
    "| ---- | ----- | ---- | ---- | ---- |\n",
    "| time | date | pd.datetime |  | accident\n",
    "|  | day of week | pd.datetime |  | accident\n",
    "|  | time of day (hour) | pd.datetime |  | accident\n",
    "| | light level | int | dark (any) = 0, dawn/dusk = 1, day = 2 | LIGHT_COND, accident\n",
    "| | | | | \n",
    "| location | node_id | int | | node |\n",
    "| | lga | string | local area | node |\n",
    "| | region | string | | node |\n",
    "| | long | float | longitude | node |\n",
    "| | lat | float | latitude | node |\n",
    "| |  | | |\n",
    "| atmospheric | 1: clear         | bool |            | atmostpheric\n",
    "|             | 2: raining       | bool |            | atmostpheric\n",
    "|             | 3: snowing       | bool |            | atmostpheric\n",
    "|             | 4: fog           | bool |            | atmostpheric\n",
    "|             | 5: smoke         | bool |            | atmostpheric\n",
    "|             | 6: dust          | bool |            | atmostpheric\n",
    "|             | 7: winds         | bool |            | atmostpheric\n",
    "|             | 9: unknown       | bool | remove unknown | atmostpheric\n",
    "| | | | |\n",
    "| road_cond   | 1: dry           | bool |           | road condition\n",
    "|             | 2: wet           | bool |           | road condition\n",
    "|             | 3: muddy         | bool |           | road condition\n",
    "|             | 4: snowy         | bool |           | road condition\n",
    "|             | 5: icy           | bool |           | road condition\n",
    "|             | 9: unknown       | bool | remove unknown  | road condition\n",
    "| | | | |\n",
    "\n",
    "labels\n",
    "\n",
    "| column name | data type | description | original dataset |\n",
    "| ----- | ---- | ---- | ---- |\n",
    "| police_needed | int | number of police for colision bin | POLICE_ATTENDED, accident |\n",
    "| ambulance_needed | int | number of ambulance needed for that colision bin | to investigate, mix of TAKEN_HOSPITAL in PERSON and if injuries are serious in ACCIDENT | \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    " ### Abulance needed\n",
    "\n",
    "assuming an ambulace is called if\n",
    "\n",
    "there are more than \n",
    "- 5 people involved in a crash ? (didnt include)\n",
    "- any person in the crash has an inj_level > 0\n",
    "- any person was taken to the hospital\n",
    "\n",
    "only calls one ambulance no matter number of people, to keep inline with number of police\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.groupby('ACCIDENT_NO')['ACCIDENTDATE'].count().sort_values()   # no duplicates for accidnets no, theyre unique\n",
    "\n",
    "\n",
    "node.groupby('ACCIDENT_NO')['NODE_ID'].count().sort_values()\n",
    "node.query('ACCIDENT_NO == \"T20170021373\"')    # dueplicated nodes per accident are due to issues with postcode double ups, not in multi location\n",
    "\n",
    "\n",
    "\n",
    "person.groupby('ACCIDENT_NO')['PERSON_ID'].count().sort_values()     # duplicate ACCIDENT_NO for multiple perople in single colision\n",
    "person.query('ACCIDENT_NO == \"T20130018492\"')   \n",
    "\n",
    "atmospheric.groupby('ACCIDENT_NO')['ATMOSPH_COND'].count().sort_values()     \n",
    "atmospheric.query('ACCIDENT_NO == \"T20190001830\"')           # several conditions like winds and rain, need to factor in, probably pivot as seperate columns\n",
    "\n",
    "\n",
    "\n",
    "road_cond.groupby('ACCIDENT_NO')['SURFACE_COND'].count().sort_values()\n",
    "road_cond.query('ACCIDENT_NO == \"T20070019368\"')          # same as atmospheric, several conditions can be met"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filtering and transforming "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date\n",
    "\n",
    "# removing na dates and times\n",
    "accidents = accidents.dropna(subset=['ACCIDENTDATE'])\n",
    "accidents = accidents.dropna(subset=['ACCIDENTTIME'])\n",
    "\n",
    "# only keeping more recent data from 2016 prior, new data will be more accurate\n",
    "accidents = accidents[pd.to_datetime(accidents['ACCIDENTDATE']) > pd.to_datetime(EARLIEST_DATE)].reset_index(drop = True)\n",
    "accidents.head(3)\n",
    "\n",
    "accidents.loc[:,'date'] = pd.to_datetime(accidents[['ACCIDENTDATE','ACCIDENTTIME']].apply(lambda x: x[0] + \" \" + x[1] , axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# light conditions\n",
    "\n",
    "accidents = accidents.query(\"LIGHT_CONDITION != 9\")\n",
    "\n",
    "accidents.loc[:,'day_light'] = accidents['LIGHT_CONDITION'].apply(lambda light_level: 3 - min(light_level, 3))    # converts conditions to 0-2 scale of daylight\n",
    "accidents.groupby('LIGHT_CONDITION')['day_light'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents = accidents.query(\"POLICE_ATTEND != 9\")   # removing when unsure if police attened or not\n",
    "\n",
    "accidents.loc[:,'police_needed'] = accidents['POLICE_ATTEND'].apply(lambda x: 2 - x)\n",
    "accidents.groupby('POLICE_ATTEND')['police_needed'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents[['ACCIDENT_NO','date','police_needed']].head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping instances with ids that exist\n",
    "person = person[person['ACCIDENT_NO'].isin(accidents['ACCIDENT_NO'])]\n",
    "\n",
    "# converting injury level to number\n",
    "person.loc[:,'injury_level'] = person['INJ_LEVEL'].apply(pd.to_numeric, errors= 'coerce')\n",
    "person = person.dropna(subset = ['injury_level'])\n",
    "\n",
    "person.loc[:,'ambulance_needed'] = person[['injury_level','TAKEN_HOSPITAL']].apply(lambda x: (x['injury_level'] < 4) or (x['TAKEN_HOSPITAL'] == 'Y'), axis = 1)    # true if not a non_injury\n",
    "\n",
    "# person.groupby(['INJ_LEVEL'])['ambulance_needed'].unique()   # data looks good\n",
    "\n",
    "# accidents where ambulance was needed\n",
    "person_grouped = person.groupby('ACCIDENT_NO')['ambulance_needed'].any()\n",
    "\n",
    "# pivots to summarize ambulance data per crash\n",
    "person_pivotted = person\\\n",
    "    .pivot_table(index = \"ACCIDENT_NO\", values = 'ambulance_needed', aggfunc = \"max\")\\\n",
    "    .fillna(0)\\\n",
    "    .applymap(lambda x: min(x, 1))\\\n",
    "    .reset_index()\n",
    "\n",
    "person_pivotted[['ACCIDENT_NO','ambulance_needed']].head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping instances with ids that exist\n",
    "node = node[node['ACCIDENT_NO'].isin(accidents['ACCIDENT_NO'])]\n",
    "\n",
    "node\n",
    "\n",
    "node.loc[:,'lat'] = node['Lat'].apply(pd.to_numeric, errors= 'coerce')\n",
    "node.loc[:,'long'] = node['Long'].apply(pd.to_numeric, errors= 'coerce')\n",
    "\n",
    "node = node.rename(columns = {'REGION_NAME': 'region', 'LGA_NAME':'lga', 'NODE_ID':'node_id'})\n",
    "\n",
    "node[['ACCIDENT_NO','node_id','lga','region_name','lat','long']].drop_duplicates().head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### road_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping instances with ids that exist\n",
    "road_cond = road_cond[road_cond['ACCIDENT_NO'].isin(accidents['ACCIDENT_NO'])]\n",
    "\n",
    "# removes unknowns\n",
    "road_cond = road_cond.query(\"SURFACE_COND != 9\")\n",
    "road_cond = road_cond.dropna(subset = ['SURFACE_COND'])\n",
    "\n",
    "# making descrions lowercase\n",
    "road_cond.loc[:,'Surface Cond Desc'] = road_cond.loc[:,'Surface Cond Desc'].str.lower()\n",
    "\n",
    "# pivots to create new columns\n",
    "road_cond_pivotted = road_cond\\\n",
    "    .pivot(index = \"ACCIDENT_NO\", columns = 'Surface Cond Desc', values = 'SURFACE_COND')\\\n",
    "    .fillna(0)\\\n",
    "    .applymap(lambda x: min(x, 1))\\\n",
    "    .reset_index()\n",
    "\n",
    "\n",
    "road_cond_pivotted[['ACCIDENT_NO', 'dry', 'icy', 'muddy', 'snowy', 'wet']].drop_duplicates().head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### atmospheric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping instances with ids that exist\n",
    "atmospheric = atmospheric[atmospheric['ACCIDENT_NO'].isin(accidents['ACCIDENT_NO'])]\n",
    "\n",
    "# removes unknowns\n",
    "atmospheric = atmospheric.query(\"ATMOSPH_COND != 9\")\n",
    "atmospheric = atmospheric.dropna(subset = ['ATMOSPH_COND'])\n",
    "\n",
    "# making descrions lowercase\n",
    "atmospheric.loc[:,'Atmosph Cond Desc'] = atmospheric.loc[:,'Atmosph Cond Desc'].str.lower()\n",
    "\n",
    "# pivots to create new columns\n",
    "atmospheric_pivotted = atmospheric\\\n",
    "    .pivot(index = \"ACCIDENT_NO\", columns = 'Atmosph Cond Desc', values = 'ATMOSPH_COND')\\\n",
    "    .fillna(0)\\\n",
    "    .applymap(lambda x: min(x, 1))\\\n",
    "    .reset_index()\n",
    "\n",
    "atmospheric_pivotted[['ACCIDENT_NO', 'clear', 'dust', 'fog', 'raining', 'smoke', 'snowing', 'strong winds']].drop_duplicates().head(3)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = accidents[['ACCIDENT_NO','date','police_needed']].drop_duplicates()\\\n",
    "    .merge(\n",
    "        node[['ACCIDENT_NO','node_id','lga','region_name','lat','long']].drop_duplicates(), \n",
    "        how='inner')\\\n",
    "    .merge(\n",
    "        road_cond_pivotted[['ACCIDENT_NO', 'dry', 'icy', 'muddy', 'snowy', 'wet']].drop_duplicates(), \n",
    "        how='inner')\\\n",
    "    .merge(\n",
    "        atmospheric_pivotted[['ACCIDENT_NO', 'clear', 'dust', 'fog', 'raining', 'smoke', 'snowing', 'strong winds']].drop_duplicates(), \n",
    "        how='inner')\\\n",
    "    .merge(\n",
    "        person_pivotted[['ACCIDENT_NO','ambulance_needed']].drop_duplicates(), \n",
    "        how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.pivot_table(\n",
    "    index = ['lga', 'region_name', 'dry', 'icy', 'muddy', 'snowy', 'wet', 'clear', 'dust',\n",
    "       'fog', 'raining', 'smoke', 'snowing', 'strong winds',\n",
    "       ],\n",
    "    values = ['police_needed', 'ambulance_needed'],\n",
    "    aggfunc = 'sum'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
