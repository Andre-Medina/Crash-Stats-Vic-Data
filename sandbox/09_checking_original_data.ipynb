{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import sys\n",
    "\n",
    "ROOT_DIR = '../'\n",
    "sys.path.insert(1, '../production_code/')\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accidents = pd.read_csv(ROOT_DIR + ACCIDENT_DATA_GENERAL_DIR)\n",
    "node = pd.read_csv(ROOT_DIR + ACCIDENT_DATA_NODE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.loc[:,'ACCIDENTDATE'] = pd.to_datetime(accidents.loc[:,'ACCIDENTDATE'], format=\"%d/%m/%Y\")\n",
    "accidents.loc[:,'DAY_OF_WEEK'] = accidents.loc[:,'ACCIDENTDATE'].dt.day_of_week"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing all the data stages\n",
    "\n",
    "by grouping and pivotting the data, any stage can be broken down into the total number of calls made each day, averaged over all days in a certain date range. The groupped by region.\n",
    "\n",
    "This way we can make sure the average number of emergency calls made in each region per day, stays constant accross all dates, as it should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_min = pd.to_datetime(TRAIN_SPLIT_MIN_DATE) #TRAIN_SPLIT_MIN_DATE\n",
    "date_max = pd.to_datetime(TEST_TRAIN_SPLIT_DATE) #TEST_SPLIT_MAX_DATE\n",
    "accidents.loc[:,'POLICE_ATTEND'] = accidents['POLICE_ATTEND'].apply(lambda x: 2 - x)\n",
    "\n",
    "accidents\\\n",
    "    .merge(node[['ACCIDENT_NO','REGION_NAME']].drop_duplicates(), how = 'inner')\\\n",
    "    .drop_duplicates(subset=['ACCIDENT_NO'])\\\n",
    "    .query('ACCIDENTDATE >= @date_min & ACCIDENTDATE < @date_max')\\\n",
    "    .pivot_table(    # sums the total number of police attended for each day, splitting by region\n",
    "         index = ['ACCIDENTDATE','REGION_NAME'],\n",
    "         values=['POLICE_ATTEND'],\n",
    "         aggfunc='sum'\n",
    "         )\\\n",
    "    .reset_index()\\\n",
    "    .groupby(['REGION_NAME'])['POLICE_ATTEND'].mean() \n",
    "    # .pivot_table(    # sums the total number of police attended for each day, splitting by region\n",
    "    #     index = ['ACCIDENTDATE'],\n",
    "    #     columns=['REGION_NAME'],\n",
    "    #     values=['POLICE_ATTEND'],\n",
    "    #     aggfunc='sum'\n",
    "    #     )\\\n",
    "    # .sort_index(ascending=False)\\\n",
    "    # .head(60)\\\n",
    "    # .mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original with basic filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidents = accidents.dropna(subset=['ACCIDENTDATE'])\n",
    "# accidents = accidents.dropna(subset=['ACCIDENTTIME'])\n",
    "# accidents = accidents.query(\"LIGHT_CONDITION != 9\")\n",
    "accidents = accidents.query(\"POLICE_ATTEND != 9\")   # removing when unsure if police attened or not\n",
    "accidents = accidents[pd.to_datetime(accidents['ACCIDENTDATE']) > pd.to_datetime(EARLIEST_DATE)].reset_index(drop = True)\n",
    "\n",
    "accidents\\\n",
    "    .merge(node[['NODE_ID','REGION_NAME']]\\\n",
    "        .drop_duplicates(), how = 'inner')\\\n",
    "    .drop_duplicates(subset=['ACCIDENT_NO'])\\\n",
    "    .query('ACCIDENTDATE >= @date_min & ACCIDENTDATE < @date_max')\\\n",
    "    .pivot_table(    # sums the total number of police attended for each day, splitting by region\n",
    "         index = ['ACCIDENTDATE','REGION_NAME'],\n",
    "         values=['POLICE_ATTEND'],\n",
    "         aggfunc='sum'\n",
    "         )\\\n",
    "    .reset_index()\\\n",
    "    .groupby(['REGION_NAME'])['POLICE_ATTEND'].mean() \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# roughly cleaned pre merge dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUGHLY_CLEANED_PRE_MERGE_DATA_DIR\n",
    "\n",
    "first_clean = pd.read_csv(ROOT_DIR + ROUGHLY_CLEANED_PRE_MERGE_DATA_DIR)\n",
    "first_clean.loc[:,'POLICE_ATTEND'] = first_clean['POLICE_ATTEND'].apply(lambda x: 2 - x)\n",
    "first_clean.loc[:,'date'] = pd.to_datetime(first_clean.loc[:,'date']).dt.date\n",
    "\n",
    "first_clean\\\n",
    "    .merge(node[['ACCIDENT_NO','REGION_NAME']]\\\n",
    "        .drop_duplicates(),  how = 'inner')\\\n",
    "    .query('date >= @date_min & date < @date_max')\\\n",
    "    .pivot_table(    # sums the total number of police attended for each day, splitting by region\n",
    "         index = ['date','REGION_NAME'],\n",
    "         values=['POLICE_ATTEND'],\n",
    "         aggfunc='sum'\n",
    "         )\\\n",
    "    .reset_index()\\\n",
    "    .groupby(['REGION_NAME'])['POLICE_ATTEND'].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "node = pd.read_csv(ROOT_DIR + ACCIDENT_DATA_NODE_DIR)\n",
    "first_clean = pd.read_csv(ROOT_DIR + ROUGHLY_CLEANED_PRE_MERGE_DATA_DIR)\n",
    "first_clean.loc[:,'date'] = pd.to_datetime(first_clean.loc[:,'date']).dt.date\n",
    "\n",
    "# only keeping instances with ids that exist\n",
    "print(\"initial shape: \" + str(node.shape))\n",
    "node = node[node['ACCIDENT_NO'].isin(accidents['ACCIDENT_NO'])]\n",
    "\n",
    "\n",
    "node = node.rename(columns = {\n",
    "    'REGION_NAME': 'region', \n",
    "    'LGA_NAME':'lga', \n",
    "    'NODE_ID':'node_id',\n",
    "    'Lat':'lat',\n",
    "    'Long':'long'\n",
    "    })\n",
    "node['region'] = node['region'].astype(str)\n",
    "node['lga'] = node['lga'].astype(str)\n",
    "node.loc[:,'lat'] = node.loc[:,'lat'].apply(pd.to_numeric)\n",
    "node.loc[:,'long'] = node.loc[:,'long'].apply(pd.to_numeric)\n",
    "\n",
    "# removing blank regions\n",
    "node = node.query('region != \" \"')\n",
    "\n",
    "accidents_of_interest = ['date']\n",
    "accidents_label_columns = ['police_needed']\n",
    "id_columns = ['ACCIDENT_NO']\n",
    "node_of_interest = ['node_id','lga','region','lat','long']\n",
    "\n",
    "\n",
    "first_clean.loc[:,'police_needed'] = first_clean['POLICE_ATTEND'].apply(lambda x: 2 - x)\n",
    "\n",
    "\n",
    "first_clean[id_columns + accidents_of_interest + accidents_label_columns].drop_duplicates()\\\n",
    "    .merge(\n",
    "        node[id_columns + node_of_interest].drop_duplicates(), \n",
    "        how='inner')\\\n",
    "    .query('date >= @date_min & date < @date_max')\\\n",
    "    .pivot_table(    # sums the total number of police attended for each day, splitting by region\n",
    "         index = ['date','region'],\n",
    "         values=['police_needed'],\n",
    "         aggfunc='sum'\n",
    "         )\\\n",
    "    .reset_index()\\\n",
    "    .groupby(['region'])['police_needed'].mean() \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_1 = pd.read_csv( ROOT_DIR + ROUGHLY_CLEANED_MERGE_1_DATA_DIR)\n",
    "stage_1.loc[:,'date'] = pd.to_datetime(stage_1.loc[:,'date']).dt.date\n",
    "\n",
    "stage_1\\\n",
    "    .query('date >= @date_min & date < @date_max')\\\n",
    "    .pivot_table(    # sums the total number of police attended for each day, splitting by region\n",
    "         index = ['date','region'],\n",
    "         values=['police_needed'],\n",
    "         aggfunc='sum'\n",
    "         )\\\n",
    "    .reset_index()\\\n",
    "    .groupby(['region'])['police_needed'].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_2 = pd.read_csv( ROOT_DIR + ROUGHLY_CLEANED_MERGE_2_DATA_DIR)\n",
    "stage_2.loc[:,'date'] = pd.to_datetime(stage_2.loc[:,'date']).dt.date\n",
    "\n",
    "stage_2\\\n",
    "    .query('date >= @date_min & date < @date_max')\\\n",
    "    .pivot_table(    # sums the total number of police attended for each day, splitting by region\n",
    "         index = ['date','region'],\n",
    "         values=['police_needed'],\n",
    "         aggfunc='sum'\n",
    "         )\\\n",
    "    .reset_index()\\\n",
    "    .groupby(['region'])['police_needed'].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_3 = pd.read_csv( ROOT_DIR + ROUGHLY_CLEANED_MERGE_2_DATA_DIR)\n",
    "stage_3.loc[:,'date'] = pd.to_datetime(stage_3.loc[:,'date']).dt.date\n",
    "\n",
    "stage_3\\\n",
    "    .query('date >= @date_min & date < @date_max')\\\n",
    "    .pivot_table(    # sums the total number of police attended for each day, splitting by region\n",
    "         index = ['date','region'],\n",
    "         values=['police_needed'],\n",
    "         aggfunc='sum'\n",
    "         )\\\n",
    "    .reset_index()\\\n",
    "    .groupby(['region'])['police_needed'].mean() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparing to initial clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_clean = pd.read_csv(ROOT_DIR + ROUGHLY_CLEANED_DATA_DIR)\n",
    "first_clean.loc[:,'date'] = pd.to_datetime(first_clean.loc[:,'date']).dt.date\n",
    "\n",
    "first_clean\\\n",
    "    .query('date >= @date_min & date < @date_max')\\\n",
    "    .pivot_table(    # sums the total number of police attended for each day, splitting by region\n",
    "         index = ['date','region'],\n",
    "         values=['police_needed'],\n",
    "         aggfunc='sum'\n",
    "         )\\\n",
    "    .reset_index()\\\n",
    "    .groupby(['region'])['police_needed'].mean() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparing to further clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_clean = pd.read_csv(ROOT_DIR + FULLY_CLEANED_DATA_DIR)\n",
    "second_clean.loc[:,'date'] = pd.to_datetime(first_clean.loc[:,'date']).dt.date\n",
    "\n",
    "second_clean\\\n",
    "    .query('date >= @date_min & date < @date_max')\\\n",
    "    .pivot_table(    # sums the total number of police attended for each day, splitting by region\n",
    "         index = ['date','region'],\n",
    "         values=['police_needed'],\n",
    "         aggfunc='sum'\n",
    "         )\\\n",
    "    .reset_index()\\\n",
    "    .groupby(['region'])['police_needed'].mean() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparing to previotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pivot = pd.read_csv(ROOT_DIR + PREPIVOT_TRAIN_TEST_DATA_DIR)\n",
    "pre_pivot.loc[:,'date'] = pd.to_datetime(pre_pivot.loc[:,'date']).dt.date\n",
    "\n",
    "pre_pivot\\\n",
    "    .query('date >= @date_min & date < @date_max')\\\n",
    "    .pivot_table(    # sums the total number of police attended for each day, splitting by region\n",
    "         index = ['date','region'],\n",
    "         values=['police_needed'],\n",
    "         aggfunc='sum'\n",
    "         )\\\n",
    "    .reset_index()\\\n",
    "    .groupby(['region'])['police_needed'].mean() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre pivotted with scaled police"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pivot\\\n",
    "    .query('date >= @date_min & date < @date_max')\\\n",
    "    .pivot_table(    # sums the total number of police attended for each day, splitting by region\n",
    "         index = ['region','sky','date'],\n",
    "         values=['scaled_police'],\n",
    "         aggfunc='sum'\n",
    "         )\\\n",
    "    .reset_index()\\\n",
    "    .pivot_table(    # sums the total number of police attended for each day, splitting by region\n",
    "         index = ['region','date'],\n",
    "         values=['scaled_police'],\n",
    "         aggfunc='mean'\n",
    "         )\\\n",
    "    .reset_index()\\\n",
    "    .groupby(['region'])['scaled_police'].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparing to final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = REGION_TESTING_DATA_DIR\n",
    "file = REGION_TRAINING_DATA_DIR\n",
    "\n",
    "test_data = pd.read_csv(ROOT_DIR + file)\n",
    "test_data\\\n",
    "    .pivot_table(      # averaging rainging or not\n",
    "        index = ['Region','Part of Day','Day of the Week'],\n",
    "        values=['Police'],\n",
    "        aggfunc='mean'\n",
    "    )\\\n",
    "    .reset_index()\\\n",
    "    .pivot_table(      # adding together parts of day\n",
    "        index = ['Region','Day of the Week'],\n",
    "        values=['Police'],\n",
    "        aggfunc='sum'\n",
    "    )\\\n",
    "    .reset_index()\\\n",
    "    .groupby(['Region'])['Police'].mean()\n",
    "# averaging each day of the week\n",
    "\n",
    "# test_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
